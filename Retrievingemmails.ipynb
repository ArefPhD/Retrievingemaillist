{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4"
      ],
      "metadata": {
        "id": "rPW7FiqZ2Xka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Send an HTTP GET request to the webpage\n",
        "url = \"https://chem-eng.utoronto.ca/faculty-staff/faculty-members/\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create a BeautifulSoup object to parse the HTML content\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Find email addresses using a regular expression pattern\n",
        "email_pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
        "emails = re.findall(email_pattern, response.text)\n",
        "\n",
        "unique_names = list(set(emails))\n",
        "unique_names = []\n",
        "[unique_names.append(name) for name in emails if name not in unique_names]\n",
        "\n",
        "unique_names\n",
        "\n",
        "# Extract last names\n",
        "last_names = [name.split()[-1] for name in unique_names]\n",
        "emails=last_names \n",
        "\n",
        "# Prepare data for CSV\n",
        "data = []\n",
        "for email in emails:\n",
        "    username = email.split(\"@\")[0]\n",
        "    data.append([username, email])\n",
        "\n",
        "# Save data to a CSV file\n",
        "filename = \"email_list.csv\"\n",
        "with open(filename, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Name\", \"Emails\"])  # Write header\n",
        "    writer.writerows(data)  # Write data rows\n",
        "\n",
        "print(\"Email list saved to\", filename)"
      ],
      "metadata": {
        "id": "fQnvndn_Kgza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails"
      ],
      "metadata": {
        "id": "kip5orEbKfc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Send an HTTP GET request to the webpage\n",
        "url = \"https://chemistry.gatech.edu/faculty\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create a BeautifulSoup object to parse the HTML content\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Find email addresses using a regular expression pattern\n",
        "email_pattern = r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"\n",
        "emails = re.findall(email_pattern, response.text)\n",
        "\n",
        "# Prepare data for CSV\n",
        "data = []\n",
        "for email in emails:\n",
        "    username = email.split(\"@\")[0]\n",
        "    data.append([username, email])\n",
        "\n",
        "# Save data to a CSV file\n",
        "filename = \"email_list.csv\"\n",
        "with open(filename, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Name\", \"Emails\"])  # Write header\n",
        "    writer.writerows(data)  # Write data rows\n",
        "\n",
        "print(\"Email list saved to\", filename)"
      ],
      "metadata": {
        "id": "S2aFlpTZ2iKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('email_list.csv') "
      ],
      "metadata": {
        "id": "JQNIa7wT3EDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Send an HTTP GET request to the webpage\n",
        "url = \"https://chemistry.gatech.edu/faculty\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Create a BeautifulSoup object to parse the HTML content\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "# Find the faculty member elements\n",
        "faculty_elements = soup.find_all(\"a\", hreflang=\"en\")\n",
        "\n",
        "# Retrieve names and email addresses\n",
        "names = []\n",
        "emails = []\n",
        "\n",
        "for element in faculty_elements:\n",
        "    # Extract the name from the \"people\" column\n",
        "    name_parts = element[\"href\"].split(\"/\")[-1].split(\"-\")\n",
        "    first_name = name_parts[0].capitalize()\n",
        "    last_name = \" \".join(name_parts[1:]).capitalize()\n",
        "    names.append(first_name + \" \" + last_name)\n",
        "\n",
        "    # Find the corresponding email address element\n",
        "    email_element = element.find_next(\"a\", class_=\"email\")\n",
        "\n",
        "    # Extract the email address if the email element is found\n",
        "    if email_element:\n",
        "        email = email_element[\"href\"].replace(\"mailto:\", \"\")\n",
        "        emails.append(email)\n",
        "\n",
        "# Prepare data for CSV\n",
        "\n",
        "unique_names = list(set(names))\n",
        "unique_names = []\n",
        "[unique_names.append(name) for name in names if name not in unique_names]\n",
        "\n",
        "unique_names\n",
        "\n",
        "# Extract last names\n",
        "last_names = [name.split()[-1] for name in unique_names]\n",
        "names=last_names \n",
        "data = list(zip(names))\n",
        "\n",
        "# Save data to a CSV file\n",
        "filename = \"faculty_list.csv\"\n",
        "with open(filename, \"w\", newline=\"\") as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Name\", \"Email\"])  # Write header\n",
        "    writer.writerows(data)  # Write data rows\n",
        "\n",
        "print(\"Faculty list saved to\", filename)"
      ],
      "metadata": {
        "id": "I628LP3C9cAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "D3d02YPq-GZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E9fPvunp-B5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jDFKiMcuACe4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}